The Structured Employment Interview: An Examination of Construct and Criterion Validity

A thesis submitted in partial fulfillment of the requirements for the degree of Master of Applied Psychology at University of Waikato by Anne B. Levine

___________________________

University of Waikato 2006

ii Abstract This study extends the literature on interview validity by attempting to create a structured employment interview with both construct- and criterion-related validity. For this study, a situational interview was developed with the specific purpose of enhancing the interview's construct validity while retaining the interview's predictive power. To enhance the construct validity, two guidelines were applied to the creation of the interview based on previous research in interview and assessment center literature--(1) limit the number of applicant characteristics to be rated to 3; and (2) ensure that the dimensions to be measured are conceptually distinct. Based on these two guidelines, three constructs were chosen for assessment of real estate sales agents--extraversion, proactive personality and customer orientation. The critical incident technique was used to develop six interview items. To test the construct validity of the interview, the six items were correlated with other measures, specifically, self-report questionnaires and managers' ratings, of extraversion, proactivity and customer orientation. Correlations were weak, at best (rs ranged from -.06 to .25). To test the predictive validity of the interview, the six items were correlated with both objective and subjective measures of performance. Predictive validities were stronger, ranging from .23 to .30. These findings are consistent with previous research on employment interviews which have found that although the predictive validity of the interview is strong, the construct validity is very weak, leaving researchers to wonder what it is that the interview is actually measuring. Possible explanations for these findings are offered, and the implications of these findings are discussed.

iii Acknowledgements There are many people who deserve recognition for their help with this project. First, and foremost, my eternally patient advisor Mike--thank you for your continuous support and encouragement. Thanks also to the architect of this study and my advisor from afar, Paul. This study could not have been done without the help and cooperation of an incredible organization of real estate agents--I am extremely grateful to all of you. Special thanks to John for organizing EVERYTHING. You should probably get part billing on the title page. Finally, thanks to my best friend Drew for listening to my stressed-out babble for 15 months and for constantly reminding me that if I would just do it, it would be done.

iv Contents Abstract Acknowledgements Contents List of Tables List of Appendices Chapter I Introduction Background The present study Constructs related to real estate sales Situational interviews Summary Method Participants and procedure Situational interview Self-report measures Managers' ratings of constructs Performance measures Results Descriptive statistics Interview correlations Performance measure correlations Discussion Hypotheses relating to construct validity Hypotheses relating to criterion validity Limitations Implications for research and practice Conclusion/Summary ii iii iv v vi 1 3 6 8 12 13 15 15 15 18 19 20 21 21 23 26 29 31 34 37 41 42 44 Interview items and response scales Manager rating scales 52 56

Chapter II

Chapter III

Chapter IV

References Appendix A Appendix B

v List of Tables Tables 1. Descriptive statistics of interview scores 2. Descriptive statistics of self-report scores 3. Descriptive statistics of managers' construct ratings 4. Descriptive statistics of performance measures 5. Correlations between interview items 6. Correlations between interview items, self-report measures and managers' construct ratings 7. Correlations between interview items and performance measures 8. Correlations between self-report measures, managers' construct ratings and performance measures Page 21 22 23 23 24 25 27 27

vi List of Appendices Appendix A. Interview items and response scales B. Manager rating scales Page 52 56

1 Chapter I: Introduction As one of the most frequently used personnel selection methods, employment interviews have become a main focus for researchers in the field of Industrial and Organizational (I/O) psychology. Throughout most of the 20th century, researchers consistently provided evidence of the low validity of the employment interview-- especially the unstructured interview (Arvey, Miller, Gould, & Burch, 1987). However, since the 1980s, researchers have turned their focus to certain characteristics of the interview (e.g. interview content, degree of structure) and have gradually altered the negative perception of the interview. Increasingly more research has been done to increase its predictive power (Salgado & Moscoso, 2002), and in the past 15 years it has been well established that the structured employment interview has relatively high criterion-related validity (e.g. Campion, Palmer, & Campion, 1997; Huffcutt & Arthur, 1994; McDaniel, Whetzel, Schmidt, & Maurer, 1994). Now that it has been shown that structured interviews can be good predictors of job performance, some researchers have taken steps towards examining the constructs captured in those interviews. As Salgado and Moscoso (2002) pointed out, the reasons why the employment interview predicts job performance remain to be explained--in other words, what exactly is the interview measuring? With this question in mind, a number of studies have been carried out to evaluate what constructs are actually being assessed (e.g. Harris, 1999; Huffcutt, Conway, Roth, & Stone, 2001a; Salgado & Moscoso, 2002). Many of these studies were metaanalyses, and due to the surprising lack of primary studies in this area, results have been meager. In addition, the foundations of these meta-analytic studies were

2 fundamentally flawed. Most researchers examined what the interviews were intended to measure--not what they actually measured. For example, studies by Huffcutt et al. (2001a) and Harris (1999) attempted to create taxonomies of possible constructs that could be assessed in employment interviews. These two studies examined previous interview research and recorded the dimensions rated in that research. They developed taxonomies including cognitive ability, personality dimensions, job knowledge, interests, person-organization fit and physical attributes. The problem with this research is that although the previous studies claimed to measure certain constructs, they reported no results of analysis to support those claims. Few studies have reported correlations between interview items and pre-established measures of the constructs those items were meant to capture. Huffcutt et al. (2001a) were only able to find correlations between interviews and established psychological measures for cognitive ability, and stated that the analysis of other constructs would have to be left for future research, as the correlations were simply not available. In this vein, construct validity has been extremely difficult to establish. The purpose of the present study was to create an interview specifically designed to maximize its construct validity and to evaluate whether it is possible to create an interview that has good construct validity and retains strong predictive power. In the following sections I will review previous construct-oriented studies, relevant assessment center research, sales selection literature and studies of situational interviews.

3 Background Construct Validity of Employment Interviews As mentioned in the previous section, interviews are designed to assess a variety of work-related characteristics; however, very few researchers have actually investigated whether or not interviews truly assess those characteristics. Based on the findings of those few studies, the major issue to arise concerning construct validity and the employment interview is the interview's apparent lack of dimensionality. In other words, interviews are often developed to assess a number of different interviewee characteristics; however, a number of research studies (discussed below) have found that interviews did not measure nearly as many characteristics as they were assumed to. A few recent studies have examined the construct validity of interviews using the multitrait-multimethod (MTMM) approach (Campbell & Fiske, 1959). The MTMM approach allows researchers to examine the correlations between different constructs as well as different measures of those constructs. The aforementioned studies used the MTMM matrix to examine the correlations between different items in different interviews in order to determine the convergent and discriminant validity of those interviews. Results were discouraging. Conway and Peneno (1999) examined the convergent and discriminant validity of two interviews used for the selection of university residence hall advisors. Items in both interviews were meant to assess five dimensions: being a role model, programming, helping skills, staff relations, and community development. An MTMM analysis showed that the convergent validity--r = .50 (average correlation among items intended to measure the same dimension across interviews) was only slightly higher than the discriminant validity--r = .48 (average correlation among items intended to measure

4 different dimensions within interviews). Other studies with even more unfavorable results found convergent validities that were lower than discriminant validities (Huffcutt, Weekley, Wiesner, Degroot, & Jones, 2001b; Van Iddekinge, Raymark, Eidson, & Attenweiler, 2004). Van Iddekinge et al. (2004) performed an MTMM analysis of interview items across two interviews and found a convergent validity (mean correlation across interviewers and within constructs) of r = .19 and a discriminant validity (mean correlation within interviewers and across constructs) of r = .32. In other words, scores on interview items did not differentiate between different dimensions--items were more likely to relate to items measuring different dimensions in the same interview than they were to items in other interviews that were meant to measure the same dimension. To further explore this dimensionality problem, some researchers have performed factor analyses to determine the number of factors being assessed in employment interviews. While most interviewers and developers of interviews believed they were tapping into a wide variety of applicant characteristics, factor analyses have revealed that these interviews were actually uni-dimensional (Arvey et al., 1987; Pulakos & Schmidt, 1995). In other words, instead of measuring the abundance of constructs it was supposed to, the interview was only tapping into one distinguishable factor. Unfortunately, it is unclear precisely what this single dimension might be. Arvey et al. (1987) created a 15-item interview for hiring sales clerks that was intended to assess four characteristics identified in a job analysis as important for the success of salespeople. Factor analysis of those items (based on a sample of 756 interviewees) revealed only one distinct factor with an eigenvalue greater than one. In another example, Pulakos and Schmitt (1995) created two

5 separate interviews designed to assess 8 different characteristics. Factor analyses of these interviews revealed only one clear factor for each interview with eigenvalues greater than one. These problems with construct validity are also found in the assessment center (AC) literature. Like the structured employment interview, the AC has enjoyed good criterion-related validity (Gaugler, Rosenthal, Thornton, & Bentson, 1987; Schmidt & Hunter, 1998). However, also like the interview, the evidence for construct validity in ACs has been less clear (Schleicher, Day, Mayes, & Riggio, 2002). Numerous researchers have reported evidence of a serious lack of construct validity in assessment centers (Bycio, Alvares, & Hahn, 1987; Lance, Lambert, Gewin, Lievens, & Conway, 2004; Lievens, 2002; Robertson, Gratton, & Sharpley, 1987; Sackett & Dreher, 1982). However, researchers in the AC field have suggested a few possible solutions to the problems leading to this construct validity issue (discussed below) and these solutions may also apply to the employment interview.

Techniques to Increase Dimension Variance One of the problems that is most frequently blamed for these construct validity findings in ACs is assessor inaccuracy resulting from poor AC design (Lievens, 2002). This `poor AC design' refers to aspects such as: the number of constructs to be measured, the distinctiveness of the constructs to be measured and the expertise of the assessor. To demonstrate this, studies have shown that once the design of the AC was altered to facilitate assessor rating processes, the construct validity was found to improve (Lievens & Conway, 2001; Woehr & Arthur, 2003). One way the design was altered was by limiting the number of dimensions to be

6 rated--the rationale being that assessors have limited information-processing capabilities and, therefore, have difficulty differentiating between a large number of performance dimensions (Lievens & Conway, 2001; Woehr & Arthur, 2003). In a study by Gaugler and Thornton (1989), assessors were responsible for rating either 3, 6, or 9 dimensions. The researchers found that the assessors who were asked to rate 3 dimensions provided more accurate ratings than those assessors asked to rate 6 or 9 dimensions. Woehr and Arthur (2003) further demonstrated the use of this strategy when they found in their meta-analysis that limiting the number of dimensions assessed led to higher convergent validity in ACs. This method of limiting the number of dimensions to be assessed translates to the interview literature as well. Ulrich and Trumbo found in 1965 that limiting the number of traits to be assessed by interviewers increased the validity of their ratings. Another design modification used to simplify the task of the assessor is to ask the assessors to rate dimensions that are conceptually distinct. In other words, the dimensions included in the AC (or the interview) should not correlate too highly with one another. This prevents assessors from confusing dimensions and also prevents overlap of the behaviors associated with dimensions. Kleinmann, Exler, Kuptsch, and Köller (1995) established that this step in designing ACs is generally effective at improving the quality of assessor ratings.

The Present Study The purpose of the present research was to develop a structured employment interview with both construct- and criterion-related validity. Historically, structured employment interview studies have focused primarily on criterion-related validity,

7 without attempting to maximize construct validity (Campion, Pursell, & Brown, 1988; Cortina, Goldstein, Payne, Davison, & Gilliland, 2000; Dougherty, Ebert, & Callender, 1986). However, more recently it was realized that understanding the constructs involved in employment interviews is potentially important as it may allow us to design interviews to achieve specific outcomes, such as high incremental validity and minimal impact on minority groups (Huffcutt et al, 2001a). It would also grant interviewers the ability and confidence to target specifically desired characteristics. By applying guidelines suggested in both interview and assessment center literature, I believe an interview can be created that will be multi-dimensional and have good construct- and criterion-related validity. I hypothesized that by applying the following guidelines to the creation of a structured interview, the interview would exhibit strong construct validity as well as retaining predictive strength: 1) limit the number of applicant characteristics to be rated to 3 2) ensure that the dimensions to be measured are conceptually distinct Construct validity would be examined by correlating interview scores with self-report questionnaires and manager ratings--all measuring the same 3 constructs. Interview scores would also be correlated with objective and subjective performance measures in order to examine the interview's predictive validity. For this study, I chose to create an interview for hiring salespeople. As Vinchur, Schippmann, Switzer, & Roth (1998) pointed out, the sales job is deserving of special attention because of its importance and prevalence. According to the Bureau of Labor Statistics (2006), there were 16,433,000 people employed in sales jobs in the United States in 2005. This is an 11% increase from 1996. Also, effective

8 selling is critical to the success of an economy, and sales is an occupation in which any improvement in selection can have a major impact on the bottom line of a company (Vinchur et al., 1998). salespeople. For this study, I focused specifically on real estate

Constructs Related to Real Estate Sales In order to choose which constructs to include in this study, previous research in sales selection was examined. A variety of characteristics have been linked to successful sales performance in selection studies. For example, characteristics include cognitive ability, personality dimensions, biodata, and motivation (Arvey et al., 1987; Ford, Walker, Churchill, & Hartley, 1987; Thoresen, Bradley, Bliese, & Thoresen, 2004; Vinchur et al., 1998). In addition to previous research, I also consulted the Occupational Information Network (O*Net) website. This site provides occupational information (e.g worker characteristics, occupational requirements) based on job analyses for a number of different occupations (Peterson, Mumford, Borman, Jeanneret, Fleishman, Levin, Campion, Mayfield, Morgeson, Pearlman, Gowing, Lancaster, Silver, & Dye, 2001). This was an important site to consult as choosing constructs and interview items based on job analyses increases the reliability, predictive validity, and fairness of interviews (Campion et al., 1988; Feild & Gatewood, 1989; Latham & Skarlicki, 1995). The O*Net website illustrated the knowledge, skills and abilities (KSAs) and tasks necessary for being a successful sales agent. This information combined with the sales literature helped to narrow down the list of constructs. Also, by applying the aforementioned criteria (limiting the number of dimensions to be rated, and ensuring that constructs are conceptually

9 distinct), I was able to complete the process of choosing constructs. In the end, three distinct constructs were decided on: extraversion, proactive personality, and customer orientation. In the sales selection literature, these constructs were all linked to performance criteria and were not found to correlate highly with each other--this latter point is the main reason why these constructs were chosen above others.

Extraversion Extraversion is a characteristic that is generally associated with success in sales. Extraverts are characterized as gregarious, energetic, friendly, positive, and outgoing--all traits that are recognized as important for successful salespeople to exhibit (Thoresen et al., 2004). O*Net describes real estate sales as a `social occupation' which requires a lot of interaction with people; therefore, displaying signs of extraversion (i.e. friendliness and being outgoing) is a desired trait for salespeople. Arvey et al. (1987) states that salespeople will be more successful if they are energetic, friendly and outgoing--again, all of which are aspects of extraversion. This finding was further supported by Barrick and Mount (1991) who found a significant predictor-criterion relationship for salespeople of .15 between extraversion and performance. Also, in a meta-analytic study of the predictors of sales success, Vinchur et al. (1998) found extraversion to be a valid predictor of both supervisory ratings of sales performance and actual sales volume. Therefore, I hypothesized the following: Hypothesis 1: Extraversion scores on the interview (Items 1 and 2) will be positively related to self-report measures and managers' ratings of extraversion.

10 Hypothesis 2: Extraversion scores on the interview will be positively related to performance.

Proactive Personality The typical proactive personality is one who is unconstrained by situational forces and who effects environmental change. Proactive personalities excel at identifying opportunities and acting on them; they show initiative and persevere until they bring about the change they desire (Bateman & Crant, 1993). They are also known to enjoy facing and overcoming obstacles--a must in an occupation such as real estate sales which is steeped with rejection. Vinchur et al. (1998) recognized rejection as one of the aspects of sales that makes it unique. They point out that as opposed to other jobs, salespeople have to deal with much greater degrees of rejection and autonomy; therefore, they must be self-starters, relying on their own initiative and drive to get the job done. Similarly, O*Net also described the job requirements of real estate sales agents to include a willingness to take on responsibilities and challenges, and persistence in the face of obstacles. In a study examining the predictive validity of the proactive personality scale for real estate sales agents, Crant (1995) found that it was a good predictor of sales performance; it explained an additional 8% of variance beyond that explained by other factors, such as experience and general mental ability. Therefore, I hypothesized the following: Hypothesis 3: Proactive personality scores on the interview (Items 3 and 4) will be positively related to self-report measures and managers' ratings of proactivity.

11 Hypothesis 4: Proactive personality scores on the interview will be positively related to performance.

Customer Orientation Customer-oriented salespeople try to help customers make purchase decisions that will satisfy customer needs. They engage in behaviors aimed at increasing customer satisfaction and creating long-term relationships with customers (as opposed to targeting the immediate sale) (Saxe & Weitz, 1982). The customer orientation scale was tested by Saxe and Weitz (1982) on 180 real estate sales agents. The results indicate that real estate agents can practice customer-oriented selling without losing sales for appearing too "soft" (Pettijohn, Pettijohn, & Parker, 1998). On the contrary, studies found that customer-oriented selling positively affected sales performance (Brown, Mowen, Donavan, & Licata, 2002; Humphreys & Williams, 1996) and appeared to help build long-term relationships--a must for real estate salespeople in a small country like New Zealand (Schultz & Good, 2000; Schwepker, 2003). Therefore, I hypothesized the following: Hypothesis 5: Customer orientation scores on the interview (Items 5 and 6) will be positively related to self-report measures and managers' ratings of customer orientation. Hypothesis 6: Customer orientation scores on the interview will be positively related to performance.

12 Situational Interviews The situational interview (SI) is one of the most popular forms of structured interviews (Harris, 1999). A meta-analysis by Huffcutt, Roth and McDaniel (1996) found that the SI was the most common type of structured interview used in interview research literature. The SI asks interviewees what they would say or do in hypothetical situations (Latham, Saari, Pursell, & Campion, 1980). Questions are developed with the purpose of exploring interviewees' intentions for future behavior. A sample SI question is as follows: "Your spouse and two teenage children are sick in bed with a cold. There are no relatives or friends available to look in on them. Your shift starts in 3 hours. What would you do in this situation?" (Latham et al., 1980, p. 424). This question would then be scored on a scale from 1 to 5 (1 being a poor response and 5 being ideal). This style of interview has been successful in predicting performance (Arvey & Campion, 1982; Latham et al., 1980). A number of studies, however, have reported another type of interview--behavior description interview (BDI)--as being a slightly better predictor of performance (Pulakos & Schmitt, 1995; Taylor & Small, 2002). BDI questions are similar to SI questions except instead of asking what the interviewee would do, the BDI asks what they did do. In other words, the BDI examines past behavior, while the SI examines intentions for future behavior. Despite the above findings, the present study used SI questions. This type of interview was chosen for one main reason--SI questions were more suitable for the sample. Real estate agents often have little or no sales experience when first entering

13 the field. For this reason, BDI questions would not be appropriate, as applicants would not have any past experiences to refer back to.

Summary The findings from researchers examining the construct validity of employment interviews have been disappointing, at best. However, by using some of the design guidelines implemented by AC developers struggling with the same construct validity problem, this study endeavored to create an interview that exhibited both construct- and criterion-related validity. I have applied the following criteria to the creation of the interview: limiting the number of constructs to be measured--in this case, limiting the constructs to be assessed to three, and ensuring that the constructs to be measured are conceptually distinct--extraversion, proactive personality, and customer-orientation, by definition, are conceptually different and should have little or no correlation with each other. I hypothesized that by applying the aforementioned criteria, the resulting interview will exhibit strong construct validity by showing positive relationships with other measures of extraversion, proactive personality and customer orientation. Specifically, I hypothesized the following: Hypothesis 1: Extraversion scores on the interview (Items 1 and 2) will be positively related to self-report measures and managers' ratings of extraversion. Hypothesis 2: Extraversion scores on the interview will be positively related to performance.

14 Hypothesis 3: Proactive personality scores on the interview (Items 3 and 4) will be positively related to self-report measures and managers' ratings of proactivity. Hypothesis 4: Proactive personality scores on the interview will be positively related to performance. Hypothesis 5: Customer orientation scores on the interview (Items 5 and 6) will be positively related to self-report measures and managers' ratings of customer orientation. Hypothesis 6: Customer orientation scores on the interview will be positively related to performance.

15 Chapter II: Method Participants and Procedure The data in this study were collected from 84 incumbent salespeople employed by a large real estate organization located in New Zealand. The mean age of participants was 46.47 years (SD = 11.7), and participants reported an average job tenure of 5.52 years (SD = 6.62). A slight majority of participants (54.8%) were women, and 45.2% were men. A large majority of the sample (86.9%) specialized in residential sales, 10.7% specialized in rural sales, and 2.4% specialized in commercial sales. The participants were drawn from 13 office branches; the number of agents participating at each branch ranged from 2 to 13. I attended staff meetings at the 13 offices to explain the purpose of the study, as well as to hand out information sheets that further described elements of the study. Agents indicated their interest by scheduling an interview time on the sign-up sheet provided. Participants were then interviewed and asked to complete a questionnaire. Both the interview and questionnaire are described below. Demographic information were also collected, concerning the participants' age, sex, job tenure, and specialization of real estate. The participants were assured of the confidentiality of their responses; interviews were conducted in private offices and all materials were returned directly to me. Measures collected from office managers were posted to the offices following my visit and returned, by post, directly to me.

Situational Interview Interview development. The situational interview used in this study was developed using a derivative of the critical incident technique. However, instead of

16 asking Subject Matter Experts (SMEs) to describe, in general, situations that result in good sales, they were asked specifically about the three desired constructs. SMEs were three real estate franchise owners/managers who had experience in hiring and supervising real estate sales agents. They were asked to provide both positive and negative critical incidents relating to extraversion, proactivity and customer orientation. For example, SMEs were asked to think of an incident in which a salesperson was particularly extraverted and it led to a good sales outcome. Twenty incidents were identified in which the above constructs were critical to a sales situation. Upon studying these incidents and weeding out those that were undesirable (e.g situations in which the desirable answer was too obvious), the number of incidents was narrowed down to six. I then worked with the managers to turn the incidents into questions and to develop response scales for each question. Managers were asked to independently benchmark responses along a 5-point scale (1 = least desired response, 3 = average response, 5 = optimal response); a group discussion ensued to reach consensus on the answers to be used as benchmarks. An example of a critical incident (for proactive personality) that was turned into an interview question is as follows:

This salesperson had a home open for inspection. He was just about to close up the house--he had another open home in 15 minutes--when a couple showed up to see the house. The agent told them that they were too late and he had to close up the house and leave. The couple ended up buying a house down the road from a competitor.

17 This incident was rewritten in the form of the following question:

You have an open home from 1 to 1.45. No one comes to see the house. As you're closing up at 1.45 a very interested buyer shows up. You have another open home at 2 (in 15 minutes). What would you do in this situation?

The managers felt that the more steps taken to work with these buyers, the better the score should be. Therefore, this question had the following benchmarks: (5) I would collect all their details right away; I'd allow them to quickly look around while I finished closing up; I would try to set up a later appointment to show them around properly; I would try to get a colleague to open my next home so that I could spend more time with these buyers right now (3) I would allow them to quickly look around and I would try to set up a later appointment to show them around properly (1) I would allow them to quickly look around. The entire interview, including response scales, is contained in Appendix A. Interview implementation. In conducting the interview, I read each question aloud and an MP3 device recorded participants' responses. Questions were repeated upon request. Interviews took between 5 and 15 minutes depending on the participant. To assess the reliability of my ratings of participants' responses, I examined the percentage agreement between me and two other raters. My two thesis advisors each independently scored 10% of the participants' responses in order to compare our ratings. The inter-rater percentage agreements were 83%, 83% and 85%. Cohen's kappa coefficients (the percentage agreements corrected for chance agreement) were

18 .77, .79 and .76. These results suggest that the initial process of rating participants was sufficiently consistent. Any disagreements were discussed until a consensus was reached.

Self-report Measures Extraversion. Extraversion was assessed using the 10-item scale from the International Personality Item Pool (IPIP) developed by Goldberg (1999). Five of the items were reverse scored as indicated in the IPIP. Goldberg's international and widely-used public domain measure has been shown to predict job performance in numerous organizational field studies (e.g. Liao & Chuang, 2004; Ployhart, Lim, & Chan, 2001). All responses were scored on a 7-point scale with response options ranging from 1 (strongly disagree) to 7 (strongly agree). This format represents a change to the original IPIP format, which uses a 5-point scale. As the IPIP scale was administered with another personality measure in my survey, I felt it was necessary to adopt a common format to avoid confusing participants (Thoresen et al., 2004). Goldberg reported an internal consistency (coefficient alpha) reliability of .86. In the present study this scale had an alpha of .72. Individual extraversion scores were converted into scale scores for analysis. The scale score was created by computing the mean extraversion score for each participant. Proactive personality. Proactive personality was assessed using the 17-item proactive personality scale developed by Bateman and Crant (1993). One item was reverse scored as indicated by Bateman and Crant. This measure has been shown to predict job performance in a number of studies (Bateman & Crant, 1993; Seibert, Crant, & Kraimer, 1999), including a study that specifically targeted real estate sales

19 agents (Crant, 1995). All responses were scored on a 7-point Likert scale with response options ranging from 1 (strongly disagree) to 7 (strongly agree). Bateman and Crant (1993) reported a coefficient alpha of .89. In the present study this scale also had an alpha of .89. Individual proactivity scores were converted into scale scores for analysis. The scale score was created by computing the mean proactivity score for each participant. Customer orientation. Customer orientation was assessed using the 24-item Selling Orientation-Customer Orientation (SOCO) scale developed by Saxe and Weitz (1982). Twelve items were reverse scored as indicated by Saxe and Weitz. This measure has been shown to predict job performance in a number of studies (Schwepker, 2003; Thomas, Soutar, & Ryan, 2001), including a study that specifically targeted real estate sales agents (Pettijohn, Pettijohn, & Parker, 1997). All responses were scored on a 9-point scale with response options ranging from 1 (true for none of your customers--NEVER) to 9 (true for all of your customers-- ALWAYS). Saxe and Weitz (1982) reported a coefficient alpha of .83. In the present study this scale had an alpha of .79. Individual customer orientation scores were converted into scale scores for analysis. The scale score was created by computing the mean customer orientation score for each participant.

Managers' construct ratings Managers' ratings of their employees on the three constructs of interest were collected with a single item for each construct on a comparative rating scale (Helson, Michels, & Sturgeon, 1954). These scales are used to rate people in comparison to other people, as opposed to absolute scales which rate people in comparison to an

20 ideal. For example, managers were asked to rate a salesperson's level of extraversion with the following question: "How extraverted (i.e. outgoing, energetic, friendly) would you say this salesperson is as compared to others you have known in real estate sales? (Place an X on the scale, indicating approximately what percentage of others this person is more extraverted than.)" 0-----10------20------30------40------50------60------70------80------90-----100% Well below average Average Well above average

For a full list of items used to assess managers' construct ratings, see Appendix B.

Performance measures To assess performance, I used both objective and subjective performance criteria. For the objective performance criteria, I used the number of sales per year. There were other options for the objective sales criteria, such as dollars in sales per year or dollars in commission per year; however, due to regional differences in property prices, I felt that number of sales was the better choice. For the subjective measure, I collected comparative performance ratings from sales managers on a single item (below and in Appendix B). "How would you rate this salesperson's overall performance as compared to others?" 0-----10------20------30------40------50------60------70------80-----90-----100% Well below average Average Well above average

21 Chapter III: Results This section first addresses the descriptive statistics of the measures used in this study. Next, I report the relationships among items within the interview and between the interview items and other measures used in this study. Finally, the predictive relationships between the different measures used in this study and performance are presented. SPSS 12.0 was used to conduct these analyses. Descriptive Statistics The means, standard deviations and skewness of interview scores are shown in Table 1. The sample size for each item is 84. Items were scored on a scale from 1 to 5 with means of: 3.19 (SD = 1.09) for item 1; 4.27 (SD = .80) for item 2; 3.17 (SD = 1.14) for item 3; 2.97 (SD = 1.01) for item 4; 3.65 (SD = 1.76) for item 5; and 4.17 (SD = .55) for item 6. On average, participants scored higher on items 2 and 6 than they did on other items. Three of the interview items (2, 4 and 5) were negatively skewed which shows that scores on those items had a tendency to congregate at one end of the scale--in this case at the high end--indicating that the distribution of those scores did not conform to a classic normal distribution. Also included in this table is a total interview score which represents the summed score across the 6 interview items. The mean total score was 21.42 (SD = 3.22) and the distribution was normal. Table 1 Means, Standard Deviation, and Skewness of Interview Scores M SD Skewness SE Skew/SE Interview Item 1 3.19 1.09 -.26 .263 -.99 Interview Item 2 4.27 .80 -.93 .263 -3.54 Interview Item 3 3.17 1.14 -.14 .263 -.53 Interview Item 4 2.97 1.01 -.67 .263 -2.55 Interview Item 5 3.65 1.76 -.60 .263 -2.28 Interview Item 6 4.17 .55 .12 .263 .46 Total interview score 21.42 3.22 -.15 .263 .57 Note. M = mean; SD = standard deviation; SE = standard error of skewness.

22 The means, standard deviations, alpha coefficients and skewness of self-report questionnaire scores are presented in Table 2. The sample size for these scores is 83. Extraversion and proactivity measures were scored on scales from 1-7, with means of 5.19 (SD = .72) and 5.65 (SD = .70), respectively. Customer orientation was scored on a scale from 1-9 with a mean of 8.0 (SD = .66). These means show that participants scored quite high on these self-report measures. Note that because the different self-report measures had different response scales, the total self-report score is a standardized score (z-score); therefore, the mean is 0. Distributions for these measures were relatively normal--with the exception of customer orientation which was negatively skewed. Table 2 Means, Standard Deviations, Reliabilities, and Skewness of Self-Report Scores M SD  Skewness SE Skew/SE Extraversion 5.19 .72 .72 -.21 .264 -.80 Proactive personality 5.65 .70 .89 -.30 .264 -1.14 Customer orientation 8.00 .66 .79 -.67 .264 -2.54 Total self-report score 0.00 2.28 -.51 .264 -1.93 Note. M = mean; SD = standard deviation;  = alpha coefficient; SE = standard error of skewness. The means, standard deviations and skewness of managers' construct ratings are presented in Table 3. The sample size for these ratings was 72. Managers rated their salespeople in extraversion, proactivity and customer orientation, on comparative percentage scales (0-100%), with means of 71.60 (SD = 14.72), 68.89 (SD = 18.86) and 72.57 (SD = 15.36), respectively. These means show that managers rated their salespeople quite high in comparison to other salespeople. Ratings were greatly skewed. The high, negative skew showed us that ratings had a tendency to congregate at the high-end of the scale, indicating that the distribution of scores did not conform to a classic normal distribution.

23 Table 3 Means, Standard Deviation, and Skewness of Managers' Construct Ratings M SD Skewness SE Skew/SE Extraversion rating 71.60 14.72 -.99 .283 -3.50 Proactivity rating 68.89 18.86 -.78 .283 -2.76 Customer orientation rating 72.57 15.36 -.85 .283 -3.00 Note. M = mean; SD = standard deviation; SE = standard error of skewness. The means, standard deviations and skewness of the performance measures are presented in Table 4. The sample size for the objective measure (annual number of sales) is 69 and the sample size for the subjective measure (managers' performance ratings) is 71. Participants' number of sales ranged from 1 to 58 with a mean of 14.51 (SD = 12.70). Performance ratings were scored on a comparative percentage scale with a mean of 68.66 (SD = 20.60). The objective measure was positively skewed, with scores having a tendency to congregate at the low end of the scale. The subjective measure was significantly negatively skewed, with scores having a tendency to congregate at the high end of the scale. Table 4 Means, Standard Deviation, and Skewness of Performance Measures M SD Skewness SE Skew/SE Number of sales 14.51 12.70 1.21 .289 4.19 Performance rating 68.66 20.60 -1.30 .285 4.56 Note. M = mean; SD = standard deviation; SE = standard error of skewness. Interview Correlations Correlations between interview items were examined to check that items intended to measure the same construct correlated with each other (in this case: items 1 and 2; 3 and 4; 5 and 6). These correlations are presented in Table 5. Items 3 and 4 had a significant, positive correlation of .26 (p < .01). However, none of the other intended pairs of items were correlated. It was originally intended that the pairs of

24 interview items would be combined into single scores, resulting in three interview scores to be used for the rest of the analysis. However, in light of these findings, remaining analyses were conducted on the 6 items separately using the six individual item scores to represent the interview, along with a combined `total interview score.' The total interview score is a summation of the individual interview items. This score was computed in order to examine its relationship with performance. Table 5 Correlations Between Interview Items 2 3 4 5 n 1 1.Interview item 1-Ext 84 2.Interview item 2-Ext 84 .17 3.Interview item 3-Pro 84 .20* .16 4.Interview item 4-Pro 84 .16 -.05 .26** 5.Interview item 5-CO 84 .08 .04 .04 -.06 6.Interview item 6-CO 84 .32** .08 .01 .13 -.04 7.Total interview score 84 .60** .39** .56** .43** .57** * p < 0.05; ** p < 0.01. Ext = extraversion; Pro = proactive personality; CO = customer orientation.

6

.32**

Correlations between interview items, self-report measures and managers' construct ratings were used to examine the relationships between the different measures. These correlations are presented in Table 6. A number of interview items significantly correlated with other measures of the same constructs, as expected. Interview item 1 (regarding extraversion) had a correlation of .25 (p < .05) with managers' ratings of extraversion, interview item 4 (regarding proactive personality) had a correlation of .22 (p < .05) with the self-report measure of proactive personality, and interview item 6 (regarding customer orientation) had a correlation of .21 (p < .05) with managers' ratings of customer orientation. I also examined the

7

8

9

10

11

measure of extraversion had a correlation of .30 (p < .01) with mangers' ratings of

relationships between the self-report measures and mangers' ratings. The self-report

Table 6 Correlations Between Interview Items, Self-Report Measures and Managers' Construct Ratings n 1 2 3 4 5 6 1.Interview item 1-Ext 84 2.Interview item 2-Ext 84 .17 3.Interview item 3-Pro 84 ..20* .16 4.Interview item 4- Pro 84 .16 -.05 .26** 5.Interview item 5- CO 84 .08 .04 .04 -.06 6.Interview item 6- CO 84 .32** .08 .01 .13 -.04 7.Self-report-Ext 83 -.06 .03 .06 .09 -.05 .10 8.Self-report-Pro 83 .04 .13 .17 .22* .03 .13 9.Self-report-CO 83 -.03 .01 .01 .21* .07 .02 10.Manager rating-Ext 72 .25* .15 .16 .07 .10 .40** 11.Manager rating-Pro 72 .20* .05 .18 -.02 .17 .33** 12.Manager rating-CO 72 .26* .13 .30** -.03 .12 .21* * p < 0.05; ** p < 0.01. Ext = extraversion; Pro = proactive personality; CO = customer orientation .42** .29** .30** -.10 -.09 .39** .22* .21* .11 .06 .07 .04

.64** .63** .75**

25

26 extraversion. Interestingly, the highest correlations found were among the self-report measures and the managers' construct ratings. Self-report scores in extraversion had correlations of .42 (p < .01) and .29 (p < .01) with self-report scores of proactivity and customer orientation, respectively, and proactivity had a correlation of .39 (p < .01) with customer orientation. Managers' ratings of extraversion had correlations of .64 (p < .01) and .63 (p < .01) with ratings of proactivity and customer orientation, respectively, and proactivity had a correlation of .75 (p < .01) with ratings of customer orientation. It seems that many of the scores were more related to the methods used as opposed to the constructs they were intended to tap into.

Performance Measure Correlations Correlations between interview items, the total interview score and performance measures were examined to determine whether or not the interview was predictive of performance. These correlations are presented in Table 7. As expected, several of the interview items and the total interview score were significantly correlated with measures of performance. Interview items 1 (extraversion), 3 (proactivity) and 6 (customer orientation) had correlations of .30 (p < .01), .23 (p < .05) and .24 (p < .05), respectively, with subjective performance measures (managers' ratings). The total interview score also had a significant correlation with managers' ratings (.28, p < .01). Interview items 2 (extraversion) and 5 (customer orientation) had correlations of .22 (p < .05) and .23 (p < .05), respectively, with objective performance measures (annual number of sales). Finally, the two different performance measures were highly correlated with each other; they had a correlation of .51 (p < .01).

5

6

7

8

-.0 4 .5 7 * * .2 3 * .0 7 P e rf =

T a b le 7 C o r r e la tio n s B e tw e e n In te r v ie w Ite m s a n d P e r fo r m a n c e M e a s u r e s n 1 2 3 4 1 .In te rv ie w ite m 1 -E x t 84 2 .In te rv ie w ite m 2 -E x t 84 .1 7 3 .In te rv ie w ite m 3 -P ro 84 .2 0 * .1 6 4 .In te rv ie w ite m 4 - P ro 84 .1 6 -.0 5 .2 6 * * 5 .In te rv ie w ite m 5 - C O 84 .0 8 .0 4 .0 4 -.0 6 6 .In te rv ie w ite m 6 - C O 84 .3 2 * * .0 8 .0 1 .1 3 7 .T o ta l in te rv ie w s c o re 84 .6 0 * * .3 9 * * .5 6 * * .4 3 * * 8 .A n n u a l s a le s 69 .1 7 .2 2 * .0 0 -.1 4 9 .M a n a g e r ra tin g -P e rf 71 .3 0 * * .0 9 .2 3 * -.0 7 * p < 0 .0 5 ; * * p < 0 .0 1 . E x t = e x tra v e rs io n ; P ro = p ro a c tiv e p e rs o n a lity ; C O = c u s to m e r o rie n ta tio n ; p e rfo rm a n c e . .3 2 * * .0 1 .2 4 * .2 0 .2 8 * *

.5 1 * *

6

7

8

T a b le 8 C o r r e la tio n s B e tw e e n S e lf-R e p o r t M e a s u r e s , M a n a g e r s ' C o n s tr u c t R a tin g s a n d P e r fo r m a n c e M e a s u r e s n 1 2 3 4 5 1 . S e lf-re p o rt-E x t 83 2 . S e lf-re p o rt-P ro 83 .4 2 * * 3 . S e lf-re p o rt-C O 83 .2 9 * * .3 9 * * 4 .T o ta l s e lf-re p o rt s c o re 8 3 .7 5 * * .8 0 * * .7 4 * * 5 . M a n a g e r ra tin g -E x t 72 .3 0 * * .2 2 * .2 1 * .3 2 * * 6 . M a n a g e r ra tin g -P ro 72 -.1 0 .1 1 .0 6 .0 3 .6 4 * * 7 . M a n a g e r ra tin g -C O 72 -.0 9 .0 7 .0 4 .0 1 .6 3 * * 8 . A n n u a l s a le s 69 -.0 8 -.0 4 .1 6 .0 2 .3 5 * * 9 . M a n a g e r ra tin g -P e rf 71 -.0 5 .0 6 .0 4 .0 1 .6 7 * * * p < 0 .0 5 ; * * p < 0 .0 1 . E x t = e x tra v e rs io n ; P ro = p ro a c tiv e p e rs o n a lity ; C O = c u s to m e r o rie n ta tio n ; P e rf = p e rfo rm a n c e .

.7 5 * * .3 9 * * .8 8 * *

.4 5 * * .8 4 * *

.5 1 * *

27

28 Lastly, correlations between self-report measures, the total self-report score, managers' construct ratings and performance measures were examined to determine whether or not the self-report measures and managers' ratings were predictive of performance. These correlations are presented in Table 8. Surprisingly, self-report measures were not significantly correlated to either of the performance measures used. However, managers' construct ratings were highly correlated to both objective and subjective measures of performance. Managers' ratings of extraversion, proactivity and customer orientation had significant correlations of .35 (p < .01), .39 (p < .01) and .45 (p < .01), respectively, with objective performance measures, and they had correlations of .67 (p < .01), .88 (p < .01) and .84 (p < .01), respectively, with subjective performance measures. In other words, managers' perceptions of their employees seem to be more closely related to employee performance than employees' self-perceptions are related to their own performance.

29 Chapter IV: Discussion The aim of the present research was to develop a structured employment interview with both construct- and criterion-related validity. The first step in this process was to examine some possible contributors to the construct validity problem in structured employment interviews. Using literature from a number of areas in organizational psychology, a couple of interview design features were identified as possibilities--particularly, (a) overloading assessors with too many dimensions to measure, and (b) asking assessors to differentiate between conceptually similar dimensions, such as reliability and conscientiousness. The next step involved using past research to establish guidelines for creating a structured employment interview with good construct validity. Following the first two steps, two guidelines were applied to the interview creation process: 1) limit the number of applicant characteristics to be rated to 3; and 2) ensure that the dimensions to be measured are conceptually distinct. Using these 2 criteria, the 3 constructs chosen were extraversion, proactive personality and customer orientation. They were chosen because of their predictive ability and because of their conceptually distinct natures. I hypothesized that by implementing the aforementioned guidelines in the creation of the interview, the resulting interview would exhibit strong construct and criterion related validity. Specifically, I hypothesized the following: Hypothesis 1: Extraversion scores on the interview (Items 1 and 2) will be positively related to self-report measures and managers' ratings of extraversion. Hypothesis 2: Extraversion scores on the interview will be positively related to performance.

30 Hypothesis 3: Proactive personality scores on the interview (Items 3 and 4) will be positively related to self-report measures and managers' ratings of proactivity. Hypothesis 4: Proactive personality scores on the interview will be positively related to performance. Hypothesis 5: Customer orientation scores on the interview (Items 5 and 6) will be positively related to self-report measures and managers' ratings of customer orientation. Hypothesis 6: Customer orientation scores on the interview will be positively related to performance. The results suggest that even when an interview is designed specifically to enhance construct validity, it is still difficult to achieve. Although some interview items were positively and significantly correlated with other measures of the same construct, most were not. In other words, interview items specifically designed to tap into certain constructs were seemingly unrelated to other measures (self-report questionnaires and manager ratings) of the same constructs. This suggests that different measures written to assess the same characteristic do not necessarily correspond. In fact, correlations between the same constructs across different methods were much lower than correlations between different constructs within methods, signifying that convergent validities were actually lower than discriminant validities--certainly not the desired outcome. However, desired or not, the results of this study suggested that scores on measures were generally determined more by the method itself than by the construct. Specifically, the highest correlations were found between the different manager ratings and the next highest were between the different

31 self-report measures. Correlations between managers' ratings of extraversion, proactivity, customer orientation and performance ranged from .63 to .88. Correlations between self-report measures of extraversion, proactivity and customer orientation ranged from .29 to .42. Correlations between different measures of the same constructs were much lower--the highest correlation found was .25. This study adds to the growing body of literature concerning the construct validity of structured employment interviews by exploring the interview development stage. I have attempted to enhance the construct validity of the employment interview by applying specific guidelines to the development stage and although it was not a complete success, there is a lot to learn from these findings--which will be discussed in detail throughout the following sections. The next section is a discussion of the specific hypotheses of this study and findings related to those hypotheses.

Hypotheses relating to construct validity The first hypothesis stated that extraversion scores on the interview would be positively related to self-report measures and managers' ratings of extraversion. This hypothesis was partially supported by the significant positive correlation found between interview item 1 and managers' ratings of extraversion. Otherwise, the different measures were generally unrelated--even the two interview extraversion items were only slightly correlated with an r of .17. It could be that participants responded differently to different measures. For example, it is possible that participants provided more `socially desirable' responses in the interviews and were then more honest in the self-report questionnaires. It makes logical sense that a

32 person would put more effort into giving the socially desirable answer when in a face-to-face situation, as opposed to a questionnaire that is anonymous. Also, Item 2 seems to be a generally weak item, with no significant correlations with self-report measures, managers' ratings or even the other interview item measure of extraversion. Item 2 was extremely negatively skewed (scores congregated at the high end of the scale) which further indicates that it was not a very good item. A likely explanation for the skewness of this item is that the item was too easy and too obvious. In other words, participants were easily able to tell what the socially desirable answer would be and therefore most participants scored very highly on this item. If so, this would explain why item 2 did not correlate with any other measures of extraversion--assuming that the other measures tapped into salespeople's actual self-perceptions of extraversion. Another possibility for the poor correlations between interview items and the other measures of extraversion may lie in the conceptualization of the construct itself. It might be difficult for a respondent to verbalize extraverted behavior, as a large part of extraversion is non-verbal. For example, extraverted people are often described as warm and energetic (Barrick & Mount, 1991; Huffcutt et al., 2001a)--traits that may be difficult to express verbally when describing what one would do in a given situation (as in a situational interview). Perhaps in an interview setting it would be more effective to rate extraversion based on the respondent's behavior during the interview as opposed to relying on a response to an item. The next hypothesis relating to construct validity, Hypothesis 3, stated that proactive personality scores on the interview would be positively related with selfreport measures and managers' ratings of proactivity. Again, this was only partially

33 supported by the significant positive correlation between interview item 4 and selfreport measures of proactivity. However, as opposed to the other pairs of interview items, items 3 and 4 were significantly correlated with each other and also had the highest correlations with their corresponding self-report measure (.17 and .22, respectively). These findings suggest that items 3 and 4 did, to some extent, tap into proactive personality. This might be due to the ease with which proactive personality can be assessed in an interview setting. Contrary to extraversion, proactive personality seems to lend itself to more accurate interview ratings. In this study, respondents were rated on proactivity based on the number of opportunities they recognized in a given situation (e.g. how many listing opportunities they identified in a picture) and by the number of solutions they produced to a given problematic situation. These basic, easily quantifiable responses could be the reason why items 3 and 4 fared so much better than the other interview items. Finally, I hypothesized (Hypothesis 5) that customer orientation scores on the interview would be positively related with self-report measures and managers' ratings of customer orientation. Yet again, this was only partially supported. There was a significant positive correlation between interview item 6 and managers' ratings of customer orientation, but otherwise correlations were extremely low. Again, as in the first hypothesis, participants might have responded differently to the different measures, perhaps by providing socially desirable responses in the interviews but not in the self-report questionnaires, leading to this discord between interview scores and self-report scores.

34 Items 5 and 6 had weaker correlations with each other than any of the other matched pairs of interview items. These findings suggest that at least one of the two items was not tapping into customer orientation as expected. However, when considering the low correlations with self-report measures, another explanation can be considered. An interesting finding by Dunlap, Dotson and Chambers (1988) was that self-perceptions and other peoples' perceptions of one's level of customer orientation can vary greatly. They found that purchasers' perceptions of the level of customer orientation of their real estate brokers were significantly different from the self-perceptions of those brokers. Specifically, real estate agents rated themselves much higher in customer orientation than their purchasers rated them. It is entirely possible that the same situation has arisen in this study, as self-report measures of customer orientation were not significantly correlated with any other measures of customer orientation. Therefore, it is likely that even if all three measures were tapping into customer orientation, due to basic differences in perceptions of this construct, it would be difficult to infer any relationships between the different measures.

Hypotheses relating to criterion validity Interestingly, although the two performance measures (objective and subjective) were significantly correlated with each other, none of the interview items had significant correlations with both measures. Two items had significant relationships with the objective measure and three items had significant relationships with the subjective measure. Although it seems somewhat puzzling, previous research has shown that the differences between objective and subjective measures of

35 performance are great enough that one should not be used as a proxy for the other (Bommer, Johnson, Rich, Podsakoff, & MacKenzie, 1995; Vinchur et al., 1998). Hypothesis 2 stated that extraversion scores on the interview would be positively related to performance. This hypothesis was supported by the significant positive correlations between interview item 1 and the subjective performance measure and interview item 2 and the objective performance measure. It is not surprising that the two interview items did not correlate with the same criterion measures, as they did not correlate very highly with each other. These results indicate that although it is not entirely clear what constructs these interview questions are tapping into, it is clear that they are predictive of real estate sales performance. This finding is consistent with previous research in this area, showing that although it is well established that interviews can have strong predictive validity, good construct validity is much more difficult to achieve (Conway & Peneno, 1999; Huffcutt & Arthur, 1994; Huffcutt et al., 2001b; McDaniel et al., 1994). These results also suggest that item 1--relating to extraversion--has a relatively strong relationship with managers' perceptions of salespeople. This can be seen by the significant correlations item 1 had with all of the manager ratings (extraversion, proactivity, customer orientation and performance). This could indicate that managers perceive extraversion as an important underlying factor of the two other constructs and performance as well. Hypothesis 4 stated that proactive personality scores on the interview would be positively related with performance. This was partially supported by a significant positive correlation between item 3 and the subjective measure of performance. On the other hand, item 4 had almost no relationship with performance, suggesting that

36 item 4 is not predictive of real estate sales performance. It is interesting that items 3 and 4 were positively related, yet only item 3 significantly correlated with performance and only item 4 significantly correlated with self-report measures of proactivity. Because item 4 correlated with self-report measures of proactivity and item 3 had only a small correlation, it is possible that it is not necessarily proactive personality that correlated with performance. These differences could indicate that interview item 3 is tapping into some variable other than proactive personality, and it could be this unknown variable which has a positive relationship with performance. In other words, these differences in predictive validity might mean that the unintended variable being measured by item 3 is the aspect of item 3 that correlates with performance and is not shared with item 4, as item 4 does not correlate with performance. Specifically what this `other' variable might be is unclear, but it would have to be something that is related to managers' perceptions of performance and not related to salespeople's self-perceptions of proactivity. Finally, hypothesis 6 stated that customer orientation scores on the interview would be positively related with performance. Support for this hypothesis exists in the form of significant positive correlations between interview item 5 and the objective performance measure, and interview item 6 and the subjective performance measure. Like items 1 and 2, it was not surprising that these items did not correlate with the same performance measures, as their relationship to each other was practically nonexistent. Also like items 1 and 2, these results indicate that although it is not entirely certain what constructs these interview questions are tapping into, it is clear that they are predictive of real estate sales performance.

37 An unexpected finding was the strong positive relationship between interview items 1 and 6. Not only were they highly correlated with each other, but they also both exhibited the same strong relationships with managers' ratings (extraversion, proactivity, customer orientation and performance). The reason for this pattern of findings is not entirely clear, but the two items could have been tapping into another, unintended construct. Upon closer examination of those two items, it seems that they were much more experience-based than any of the other items. The situations presented in those questions were very specific to real estate sales situations, whereas the other four items were much more general. It could be that items 1 and 6 were actually measuring an aspect of experience or job knowledge, and since experience and job knowledge are both good predictors of sales performance (Crant, 1995; Ford, Walker, Churchill, & Hartley, 1987), this might explain those items' relationships with performance measures.

Limitations Before the limitations of this study are discussed, there is one, very important strength of this study that deserves mention--the interview development process. The critical incident technique was used to develop the interview items. Prospective interview items were then discussed with managers of real estate offices and also with two organizational psychologists. This is a major strength of this study because in much of the previous research on the construct validity of interviews, researchers examined interviews and datasets that already existed (Conway & Peneno, 1999; Huffcutt et al., 2001a; Huffcutt et al., 2001b). Therefore, researchers did not have any input into the developmental stage of the interviews, and had no control over the

38 process by which interview items were created. The interview development stage of this study was led by the researcher. This ensures that interview items were developed in an appropriate manner. Several potential weaknesses of the present study also deserve mention. First, it should be noted that there are a number of possible, even likely, problems with the performance measures used in this study. Problems with performance data are common in sales studies (Thoresen et al., 2004) and this study was no different. Total number of annual sales--the objective measure used--is subject to regional differences. Depending on the salesperson's location, he/she might expect to sell three big farms every year or three small houses every month. However, taking this into consideration, I still feel it was the best option for an objective measure of performance, as anything with dollar amounts would have been even more subject to regional differences. Another problem with using an objective measure of performance was the tenure of participants. Many of the salespeople who participated in this study were new (30% had been there for 6 months or less) and therefore had far fewer sales than participants who had sales data for an entire year. Another issue with this measure of performance is that it is only a snapshot of a career, not the whole picture. Some of the participants had been in their jobs for more than 20 years--hence, their total number of sales for one year was not exactly a complete picture of their performance. The subjective measure of performance was problematic as well. The main issue with managers' ratings of performance was that most salespeople were rated very high. The average performance rating was 70 out of 100 on a comparative rating scale. This means that the average participant in this study performs better than 70% of salespeople. This seems highly unlikely.

39 A second potential limitation of this study was its reliance on managers. Managers were relied upon to provide ratings of extraversion, proactive personality, customer orientation and performance. Correlations between these ratings were the highest in the study, indicating that managers did not differentiate between the different constructs. I think it is likely that managers did not fully understand the meanings of each construct and probably just rated their good performers high in everything. I also considered the converse--with managers automatically rating people they felt were high in extraversion, proactivity or customer orientation highly in everything else. However, managers were probably more likely to understand the performance construct better than any of the other three; so, I believe they would have formed their ratings of extraversion, proactivity and customer orientation based on those ideas of performance rather than the converse. Another possible shortcoming of this study concerns the interview items. An analysis of descriptive statistics found that 3 of the 6 interview items were negatively skewed. In other words, responses to those 3 items had a tendency to congregate at the high end of the response scale. This could be due to the items being too easy or the desired responses being too obvious, leading to the majority of participants scoring very highly on those items. A consideration that should be addressed is assessor training. Research in assessment centers and interviews has found that better dimensionality can be expected when the assessors are more experienced and better trained (Lievens & Conway, 2001; Schleicher et al., 2002). For example, better dimension variance has been found for assessors with a degree in psychology (Lievens & Conway, 2001; Sagie & Magnezy, 1997). Lievens (2002) found that even I/O psychology students

40 outperformed managers in terms of providing ratings for different dimensions. Similarly, assessors who have received assessor training produced a higher quality of construct measurement (Lievens & Conway, 2001). Specifically, frame-of-reference (FOR) training has been shown to improve construct validity ratings of ACs (Schleicher et al., 2002). The main purpose of FOR training, which is also necessary for assessors of interviews, is to gain an understanding of the dimensions being assessed and the behaviors indicative of those dimensions. In this sense, assessors are less likely to misunderstand responses and more likely to assign responses to the appropriate behaviors. In this study, the assessor (the author) was a graduate student in psychology who had been studying the constructs to be measured for a number of months. However, I did not receive any formal FOR training and this may have negatively affected the interview scores. One final limitation was the situational interview (SI). SI questions were used in this study, as opposed to behavior description interview (BDI) questions, because of the sample being studied. Real estate sales people often have little or no real estate sales experience when they first enter the field and therefore I felt using BDI questions would be inappropriate. However, if this study were to be replicated with a different sample, it might help to use a BDI instead of a SI. Some studies have found that the BDI exhibits stronger predictive validity (Huffcutt et al., 2001b; Pulakos & Schmitt, 1995; Taylor & Small, 2002) and therefore, using BDI questions instead of SI questions might lead to a more valid study.

41 Implications for research and practice There are a number of implications of this study for both research and practice. They are discussed below. The issue of choosing performance criteria will probably always exist. Different researchers, different managers and different organizations will all have different ideas of what "performance" means and how it should be represented. Many researchers, when studying the validities of selection tests, use the term "performance" as their criteria without noting the expansive list of outcomes, actions, and nonactions this term could encompass. The obvious problem in this situation is that it is extremely difficult to judge the predictive validity of a measure if the criterion is always different and if the criterion itself is difficult to measure adequately. Only once the performance criteria are specifically defined can the appropriate selection test most effectively be chosen. As stated by Borman, Hanson, and Hedge (1997), "The criterion domain should be carefully mapped, just as various predictor areas have already been" (p.302). Subsequently, I think researchers and practitioners, when choosing performance criteria, should discard general performance and focus on a specific aspect of performance that is important to them or to their organization. Another consideration for researchers concerns training. As mentioned before, assessor training (e.g. FOR training) can have a large, positive impact on the quality of ratings obtained from those assessors (Lievens & Conway, 2001; Schleicher et al., 2002). Future studies of this type should consider using formal training for managers who must perform assessments and FOR training for the

42 interview assessors. This is likely to increase the validity of their ratings and therefore increase the validity of the study. Future research also might benefit from using a more experienced interview developer. Although the steps taken in the interview development process were a strength of this study, it was possibly due to my inexperience that some of the interview items were too easy and some of the response scores were skewed. A more experienced interview developer would perhaps create better items and better response scales which would lead to a more valid study. This recommendation translates to the practitioner as well. Organizations should ensure that they hire experienced test developers when examining selection methods and theories. One final practical implication of my results deserves some comment. The results of this study showed the convergent validities to be lower than the discriminant validities. In other words, this study found that the selection method being used is often more closely related to a respondent's score then the actual construct being measured--a common finding in the AC literature (Bycio et al., 1987; Sackett & Dreher, 1982). In reference to this finding, organizations should use a wide range of selection measures to ensure that they get a number of different scores for each applicant. That way, they can view a more complete picture of each applicant and can see how they perform in a number of different exercises.

Conclusion/Summary The results of this study provide further evidence that interviews suffer from a lack of construct validity. These findings support a number of other studies in the interview literature that have also found a lack of clear dimensions in interviews

43 (Conway & Peneno, 1999; Huffcutt et al., 2001b; Van Iddekinge et al., 2004). Specifically, only the interview items measuring proactive personality had correlations with each other and only three interview items had correlations (albeit weak correlations) with other measures assessing the same construct. However, despite these findings, I think there is still a chance that an interview can be created with strong construct validity. Specifically, the guidelines used for interview development in this study--limiting the number of dimensions to be assessed and ensuring that dimensions are conceptually distinct--provided some basis for future research. The utility of those guidelines has been argued for and supported for many years in both AC and interview literature (Gaugler & Thornton, 1989; Ulrich & Trumbo, 1965; Woehr & Arthur, 2003). This study attempted to use those guidelines to create an interview with strong construct- and criterion-related validity, and although some of the hypotheses were unsupported, I believe that by altering a few aspects of this study (as mentioned in the `implications' section) a replication of this study would yield much more positive results.

44 References Arvey, R. D., & Campion, J. E. (1982). The employment interview: A summary and review of recent research. Personnel Psychology, 35, 281-322. Arvey, R. D., Miller, H. E., Gould, R., & Burch, P. (1987). Interview validity for selecting sales clerks. Personnel Psychology, 40, 1-12. Barrick, M. R., Patton, G. K., & Haugland, S. N. (2000). Accuracy of interviewer judgments of job applicant personality traits. Personnel Psychology, 53, 925951. Barrick, M. R., & Mount, M. K. (1991). The Big Five personality dimensions and job performance: A meta-analysis. Personnel Psychology, 44, 1-26. Bateman, T. S., & Crant, J. M. (1993). The proactive component of organizational behavior: A measure and correlates. Journal of Organizational Behavior, 14, 103-118. Bommer, W. H., Johnson, J. L., Rich, G. A., Podsakoff, P. M., & MacKenzie, S. B. (1995). On the interchangeability of objective and subjective measures of employee performance: A meta-analysis. Personnel Psychology, 48, 587-605. Borman, W. C., Hanson, M. A., & Hedge, J. W. (1997). Personnel selection. Annual Review of Psychology, 48, 299-337. Brown, T. J., Mowen, J. C., Donavan, T., & Licata, J. W. (2002). The customer orientation of service workers: Personality trait effects on self- and supervisor performance ratings. Journal of Marketing Research, 39, 110-119. Bureau of Labor Statistics. (2006). Employed and unemployed persons by occupation, not seasonally adjusted, 1996, 2005. Retrieved from World Wide Web: http://www.bls.gov/cps/cpstabs.htm Bycio, P., Alvares, K. M., & Hahn, J. (1987). Situational specificity in assessment center ratings: A confirmatory factor analysis. Journal of Applied Psychology, 72, 463-474. Campbell, D. T., & Fiske, D. W. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. Psychological Bulletin, 56, 81-105. Campion, M. A., Palmer, D. K., & Campion, J. E. (1997). A review of structure in the selection interview. Personnel Psychology, 50, 655-702.

45 Campion, M. A., Pursell, E. D., & Brown, B. K. (1988). Structured interviewing: Raising the psychometric properties of the employment interview. Personnel Psychology, 41, 25-42. Cook, K. W., Vance, C.A., & Spector, P. E. (2000). The relation of candidate personality with selection-interview outcomes. Journal of Applied Social Psychology, 30, 867-885. Conway, J. M., & Peneno, G. M. (1999). Comparing structured interview question types: Construct validity and applicant reactions. Journal of Business and Psychology, 13, 485-506. Cortina, J. M., Goldstein, N. B., Payne, S. C., Davison, H. K., & Gilliland, S. W. (2000). The incremental validity of interview scores over and above cognitive ability and conscientiousness scores. Personnel Psychology, 53, 325-351. Crant, J. M. (1995). The proactive personality scale and objective job performance among real estate agents. Journal of Applied Psychology, 80, 532-537. Dougherty, T. W., Ebet, R. J., & Callender, J. C. (1986). Policy capturing in the employment interview. Journal of Applied Psychology, 71, 9-15. Dunlap, B. J., Dotson, M. J., & Chambers, T. M. (1988). Perceptions of real-estate brokers and buyers: A sales-orientation, customer-orientation approach. Journal of Business Research, 17, 175-187. Field, H. S., & Gatewood, R. D. (1989). Development of a selection interview: A job content strategy. In R. W. Eder, & G. R. Ferris (Eds.), The employment interview: Theory, research, and practice. Newbury Park, CA:Sage. Ford, N. M., Walker, O. C., Churchill, G. A., & Hartley, S. W. (1987). Selecting successful salespeople: A meta-analysis of biographical and psychological selection criteria. In M. J. Houston (Ed.), Review of Marketing (pp. 90-131). Chicago: American Marketing Association. Gangestad, S. W., & Snyder, M. (2000). Self-monitoring: Appraisal and reappraisal. Psychological Bulletin, 126, 530-555. Gatewood, R. D., & Field, H. S. (Eds.) (2001). Human Resource Selection (5th ed.). Fort Worth: Harcourt College Publishers.

46 Gaugler, B. B., Rosenthal, D. B., Thornton, G. C., & Bentson, C. (1987). Metaanalysis of assessment center validity. Journal of Applied Psychology, 72, 493-511. Gaugler, B. B., & Thornton, G. C. (1989). Number of assessment center dimensions as a determinant of assessor accuracy. Journal of Applied Psychology, 74, 611-618. Goldberg, L. R. (1999). A broad-bandwidth, public domain, personality inventory measuring the lower-level facets of several five-factor models. In I. Mervielde, I. Deary, F. De Fruyt, & F. Ostendorf (Eds.), Personality Psychology in Europe, Vol. 7 (pp. 7-28). Tilburg, The Netherlands: Tilburg University Press. Harris, M. M. (1989). Reconsidering the employment interview: A review of recent literature and suggestions for future research. Personnel Psychology, 42, 691726. Harris, M. M. (1999). What is being measured? In R. W. Eder & M. M. Harris (Eds.), The employment interview handbook (pp. 143-157). Thousand Oaks, CA: Sage. Helson, H., Michels, W. C., & Sturgeon, A. (1954). The use of comparative rating scales for the evaluation of psychophysical data. American Journal of Psychology, 67(2), 321-326. Huffcutt, A. I. & Arthur, W., Jr. (1994). Hunter and Hunter (1984) revisited: Interview validity for entry-level jobs. Journal of Applied Psychology, 79, 184-190. Huffcutt, A. I., Conway, J. M., Roth, P. L., & Stone, N. J. (2001a). Identification and meta-analytic assessment of psychological constructs measured in employment interviews. Journal of Applied Psychology, 86, 897-913. Huffcutt, A. I., Roth, P. L., & McDaniel, M. A. (1996). A meta-analytic investigation of cognitive ability in employment interview evaluations: Moderating characteristics and implications for incremental validity. Journal of Applied Psychology, 81, 459-473.

47 Huffcutt, A. I., Weekley, J. A., Wiesner, W. H., Degroot, T. G., & Jones, C. (2001b). Comparison of situational and behavior description interview questions for higher-level positions. Personnel Psychology, 54, 619-644. Humphreys, M., & Williams, M. R. (1996). Exploring the relative effects of salesperson interpersonal process attributes and technical product attributes on customer satisfaction. Journal of Personal Selling and Sales Management, 16(3), 47-57. International Personality Item Pool (2001). A scientific collaboratory for the development of advanced measures of personality traits and other indicidual differences (http://ipip.ori.org/). Internet web site. Kleinmann, M., Exler, C., Kuptsch, C., & Köller, O. (1995). Unabhängigkeit und Beobachtbarkeit von Anforderungs dimensionen im Assessment Center als Moderatoren der Konstruktvalidität [Independence and observability of dimensions as moderators of construct validity in the assessment center]. Zeitschrift für Arbeits-und Organisationspsychologie, 39, 22-28. Lance, C. E., Lambert, T. A., Gewin, A. G., Lievens, F., & Conway, J. M. (2004). Revised estimates of dimension and exercise variance components in assessment center postexercise dimension ratings. Journal of Applied Psychology, 89(2), 377-385. Latham, G. P., Saari, L. M., Pursell, E. D., & Campion, M. A. (1980). The situational interview. Journal of Applied Psychology, 65, 422-427. Latham, G. P., & Skarlicki, D. P. (1995). Criterion-related validity of the situational and patterned behavior description interview with organizational citizenship behavior. Human Performance, 8, 67-80. Liao, H., & Chuang, A. (2004). A multilevel investigation of factors influencing employee service performance and customer outcomes. Academy of Management Journal, 47, 41-58. Lievens, F. (2002). Trying to understand the different pieces of the construst validity puzzle of assessment centers: An examination of assessor and assessee effects. Journal of Applied Psychology, 87(4), 675-686.

48 Lievens, F., & Conway, J. M. (2001). Dimension and exercise variance in assessment center scores: A large-scale evaluation of multitrait-multimethod studies. Journal of Applied Psychology, 86, 1202-1222. McDaniel, M. A., Morgeson, F. P., Finnegan, E. B., Campion, M. A., & Braverman, E. P. (2001). Use of situational judgment tests to predict job performance: A clarification of the literature. Journal of Applied Psychology, 86, 730-740. McDaniel, M. A., Whetzel, D. L., Schmidt, F. L., & Maurer, S. D. (1994). The validity of employment interviews: A comprehensive review and metaanalysis. Journal of Applied Psychology, 79, 599-616. Motowidlo, S. J., Carter, G. W., Dunnette, M. D., Tippings, N., Werner, S., Burnett, J. R., & Vaughan, M. J. (1992). Studies of the structured behavioral interview. Journal of Applied Psychology, 77, 571-587. Occupational Information Network (2005). Summary Report for: Real Estate Sales Agents. Retrieved from World Wide Web: http://www.onetcenter.org Peterson, N. G., Mumford, M. D., Borman, W. C., Jeanneret, P. R., Fleishman, E. A., Levin, K. Y., Campion, M. A., Mayfield, M. S., Morgeson, F. P., Pearlman, K., Gowing, M. K., Lancaster, A. R., Silver, M. B., & Dye, D. M. (2001). Understanding work using the Occupational Information Network (O*Net): Implications for practice and research. Personnel Psychology, 54, 451-494. Pettijohn, C. E., Pettijohn, L. S., & Parker, R. S. (1997). An exploratory analysis of the inpacy of salesperson customer-orientation on sales force productivity. Jouran of Customer Service in Marketing & Management, 3(4), 5-25. Ployhart, R. E., Lim, B., & Chan, K. (2001). Exploring relations between typical and maximum performance ratings and the five factor model of personality. Personnel Psychology, 54, 809-843. Posthuma, A. R., Morgeson, F.P., & Campion, M.A. (2002). Beyond employment interview validity: A comprehensive narrative review of recent research and trends over time. Personnel Psychology, 55, 1-81. Pulakos, E. D., & Schmitt, N. (1995). Experienced-based and situational interview questions: Studies of validity. Personnel Psychology, 48, 289-308.

49 Raza, S. M., & Carpenter, B. N. (1987). A model of hiring decisions in real employment interviews. Journal of Applied Psychology, 72, 596-603. Reilly, R. R., Henry, S., & Smither, J. W. (1990). An examination of the effects of using behavior checklists on the constrict validity of assessment center dimensions. Personnel Psychology, 43, 71-84. Robertson, I., Gratton, L., & Sharpley, D. (1987). The psychometric properties and design of managerial assessment centres: Dimensions into exercises won't go. Journal of Occupational Psychology, 60, 187-195. Sacket, P. R., & Dreher, G. F. (1982). Constructs and assessment center dimensions: Some troubling empirical findings. Journal of Applied Psychology, 67, 401410. Sagie, A., & Magnezy, R. (1997). Assessor type, number of distinguishable dimension categories, and assessment centre construct validity. Journal of Occupational and Organizational Psychology, 70, 103-108. Salgado, J. F., & Moscoso, S. (2002). Comprehensive meta-analysis of the construct validity of the employment interview. European Journal of Work and Organizational Psychology, 11, 299-324. Saxe, R., & Weitz, B. A. (1982). The SOCO scale: A measure of the customer orientation of salespeople. Journal of Marketing Research, 19, 343-351. Schleicher, D. J., Day, D. V., Mayes, B. T., & Riggio, R. E. (2002). A new frame for frame-of-reference training: Enhancing the constrict validity of assessment centers. Journal of Applied Psychology, 87, 735-746. Schmidt, F. L., & Hunter, J. E. (1992). Development of a causal model of processes determining job performance. Current Directions in Psychological Science, 1, 89-92. Schmidt, F. L., & Hunter, J. E. (1998). The validity and utility of selection methods in personnel psychology: Practical and theoretical implications of 85 years of research findings. Psychological Bulletin, 124, 262-274. Schultz, R. J., & Good, D. J. (2000). Impact of the consideration of future sales consequences and customer-oriented selling on long-term buyer-seller relationships. Journal of Business & Industrial Marketing, 15(4), 200-215.

50 Schwepker, C. H. (2003). Customer-oriented selling: A review, extension, and directions for future research. Journal of Personal Selling & Sales Management, 23(2), 151-171. Seibert, S. E., Crant, J. M., & Kraimer, M. L. (1999). Proactive personality and career success. Journal of Applied Psychology, 84, 416-427. Snyder, M. (1974). Self-monitoring of expressive behavior. Journal of Personality and Social Psychology, 30, 526-537. Snyder, M. (1979). Self-monitoring processes. In L. Berkowitz (Ed.), Advances in experimental social psychology (Vol. 12, pp. 85-128). New York: Academic Press. Sternberg, R. J., Conway, B. E., Ketron, J. L., & Bernstein, M. (1981). People's conceptions of intelligence. Journal of Personality and Social Psychology, 41, 37-55. Stevens, M. J., & Campion, M. A. (1999). Staffing work teams: Development and validation of a selection test for teamwork settings. Journal of Management, 25, 207-228. Taylor, P. J., & Small, B. (2002). Asking applicants what they would do versus what they did do: A meta-analytic comparison of situational and past behavior employment interview questions. Journal of Occupationsl and Organizational Psychology, 75, 277-294. Thoresen, C. J., Bradley, J. C., Bliese, P. D., & Thoresen, J. D. (2004). The big five personality traits and individual job performance growth trajectories in maintenance and transitional job stages. Journal of Applied Psychology, 89, 835-853. Ulrich, L., & Trumbo, D. (1965). The selection interview since 1949. Psychological Bulletin, 63, 100-116. Van Iddekinge, C. H., Raymark, P. H., Eidson Jr., C. E., & Attenweiler, W. J. (2004). What do structured selection interviews really measure? The construct validity of behavior description interviews. Human Performance, 17, 71-93.

51 Vinchur, A. J., Schippmann, J. S., Switzer, F. S., & Roth, P. L. (1998). A metaanalytic review of predictors of job performance for salespeople. Journal of Applied Psychology, 83, 586-597. Woehr, D. J., & Arthur, W., Jr. (2003). The construct-related validity of assessment center ratings: A review and meta-analysis of the role of methodological factors. Journal of Management, 29, 231-258.

52 Appendix A Interview questions 1. Simulate a listing presentation. You were asked by a prospective vendor to do an appraisal of his/her house. You have only met briefly over the phone to set up this appointment. You have just arrived at his/her house. What would you do in this situation? 5-smile and be friendly; try to build rapport so they like me; point out good stuff about house (be positive about house); ask questions and chat about personal things (i.e. pictures on the wall, trophies around the house, hobbies) 4- try to build rapport so they like me; point out good stuff about house (be positive about house); ask questions and chat about personal things (i.e. pictures on the wall, trophies around the house, hobbies) 3- ask questions and chat about personal things (i.e. pictures on the wall, trophies around the house, hobbies) OR point out good stuff about house (be positive about house) 2-ask questions, but only property related 1-all business 2. Your boss has instructed you to go hand out 100 flyers in your focus marketing area. You have just enough time to hand out the 100 flyers before you must stop for an appointment. As you approach one of the houses in your area you see that someone is outside on their front lawn. What would you do in this situation? 5-I would introduce myself; have a personal chat; hand over and explain flyer 4-I would introduce myself; hand over the flyer and chat about real estate 3- I would hand over the flyer personally

53 2- I would say hello and/or smile; put the flyer in their mailbox 1- I would put the flyer in their mailbox 3. Present this picture of a street:

Ask: You need to generate business in your focus marketing area. These are the first four houses out of 100 that you want to reach today. Your boss recommended handing out flyers. What would you do to generate business? (The more answers the better). 5-5+ answers 4-4 answers 3-3 answers 2-2 answers 1-1 answer 4. You have an open home from 1 to 1.45. No one comes to see the house. As you're closing up at 1.45 a very interested buyer shows up. You have another open home at 2 (in 15 minutes). What would you do in this situation?

54 5- I would allow them to quickly look around while I finished closing up; I would try to set up a later appointment to show them around properly; I would try to get a colleague to open my next home so that I could spend more time with these buyers right now; and I would invite them to the 2pm open home 4- I would allow them to quickly look around; I would try to set up a later appointment to show them around properly; EITHER I would try to get a colleague to open my next home so that I could spend more time with these buyers right now OR I would invite them to the 2pm open home 3- I would allow them to quickly look around and I would try to set up a later appointment to show them around properly 2- I would EITHER invite them to the 2pm open home OR try to set up an appointment to show them later 1- I would allow them to quickly look around until I was ready to leave 5. You have a buyer looking for an investment property. You have a property that fits your client's investment needs in every way except that there are some unruly neighbors that have caused other tenants to leave in the past--otherwise the property is perfect. If the buyer purchases this property you will make a $10,000 commission immediately. What would you do in this situation? 5-I would tell the investor about this property, but be honest and tell them about the neighbors and problematic history in order for the buyer to make an informed decision 4- I would tell the investor about the property, tell them about the history with the neighbors and tell them not to buy 3-I wouldn't tell the investor about the property at all

55 2-I would tell the investor about the property and play down the neighbors and problematic history 1-I would tell the investor about the property but I wouldn't tell him/her about the neighbors and problematic history 6. You have a somewhat naïve vendor who is selling a property worth approximately $1 million. You have an early offer from a buyer of $890,000. If the vendor accepts this offer you will make a $14,000 commission immediately. The vendor is looking to you for advice. What would you do in this situation? 5-I would explain the pros and cons (depending on the vendor's situation) of accepting an early bid (in other words, work with vendor to decide what to do) 4-I would advise the vendor to allow me to negotiate (countersign with $1 million) 3-I would leave it up to the vendor 2-I would advise the vendor to countersign with a low figure (higher than $890,000, but still low) 1-I would advise the vendor to accept the offer of $890,000

56 Appendix B Manager rating scales 1. How extraverted (i.e. outgoing, energetic, friendly) would you say this salesperson is as compared to others you have known in real estate sales? (Place an X on the scale, indicating approximately what percentage of others this person is more extraverted than.) 0------10-------20-------30-------40-------50-------60-------70-------80------90------100% Well below average Average Well above average 2. How proactive (i.e. always scanning for opportunities, good at overcoming obstacles, showing initiative) would you say this salesperson is as compared to others? 0------10-------20-------30-------40-------50-------60-------70-------80------90------100% Well below average Average Well above average 3. How would you rate this salesperson's customer orientation (i.e. helps clients make good purchase decisions, creates long term relationships with clients, keeps customers' best interests in mind) as compared to others? 0------10-------20-------30-------40-------50-------60-------70-------80------90------100% Well below average Average Well above average 4. How would you rate this salesperson's overall performance as compared to others? 0------10-------20-------30-------40-------50-------60-------70-------80------90------100% Well below average Average Well above average

